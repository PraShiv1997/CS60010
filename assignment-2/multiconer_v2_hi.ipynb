{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "#from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coarse_tag(tag):\n",
    "  LOC = ['Facility', 'OtherLOC', 'HumanSettlement', 'Station']\n",
    "  CW = ['VisualWork', 'MusicalWork', 'WrittenWork', 'ArtWork', 'Software']\n",
    "  GRP = ['MusicalGRP', 'PublicCORP', 'PrivateCORP', 'AerospaceManufacturer', 'SportsGRP', 'CarManufacturer', 'ORG']\n",
    "  PER = ['Scientist', 'Artist', 'Athlete', 'Politician', 'Cleric', 'SportsManager', 'OtherPER']\n",
    "  PROD = ['Clothing', 'Vehicle', 'Food', 'Drink', 'OtherPROD']\n",
    "  MED = ['Medication/Vaccine', 'MedicalProcedure', 'AnatomicalStructure', 'Symptom', 'Disease']\n",
    "  if tag in LOC:\n",
    "    return('Location')\n",
    "  elif tag in CW:\n",
    "    return('CreativeWork')\n",
    "  elif tag in GRP:\n",
    "    return('Group')\n",
    "  elif tag in PER:\n",
    "    return('Person')\n",
    "  elif tag in PROD:\n",
    "    return('Product')\n",
    "  elif tag in MED:\n",
    "    return('Medical')\n",
    "  elif tag == 'O':\n",
    "    return('O')\n",
    "  else:\n",
    "    return('<PAD>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(file):\n",
    "  unclean_txt = re.compile(\"^#|[\\n]\")\n",
    "  data = []\n",
    "  with open(file) as f:\n",
    "      sent = []\n",
    "      for i in f.read().splitlines():\n",
    "          if unclean_txt.match(i) == None:\n",
    "              s = i.split(' _ _ ')[0]\n",
    "              t = i.split(' _ _ ')[-1]\n",
    "              if s!='' and t != '':\n",
    "                if t != 'O':\n",
    "                  t = t[2:]\n",
    "                z = coarse_tag(t)\n",
    "                sent.append((s,t,z))\n",
    "          if unclean_txt.match(i):\n",
    "              data.append(sent)\n",
    "              sent = []\n",
    "      data.append(sent)\n",
    "  data = data[1:] # first line had a new line character\n",
    "  return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset('/home/friday/Documents/MS/Coursework/1st Sem/Deep Learning/DL23-CS60010/assignment-2/multiconer2023/HI-Hindi/hi_train.conll')\n",
    "dev_dataset = make_dataset('/home/friday/Documents/MS/Coursework/1st Sem/Deep Learning/DL23-CS60010/assignment-2/multiconer2023/HI-Hindi/hi_dev.conll')\n",
    "test_dataset = make_dataset('/home/friday/Documents/MS/Coursework/1st Sem/Deep Learning/DL23-CS60010/assignment-2/multiconer2023/HI-Hindi/hi_test.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('यह', 'O', 'O'),\n",
       " ('झियान', 'HumanSettlement', 'Location'),\n",
       " ('चीन', 'HumanSettlement', 'Location'),\n",
       " ('के', 'O', 'O'),\n",
       " ('केंद्र', 'O', 'O'),\n",
       " ('भाग', 'O', 'O'),\n",
       " ('में', 'O', 'O'),\n",
       " ('स्थित', 'O', 'O'),\n",
       " ('है।', 'O', 'O')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.0\n"
     ]
    }
   ],
   "source": [
    "s = [[token.lower() for token, fine_tag, coarse_tag  in sentence] for sentence in train_dataset]\n",
    "l = np.array(list(map(len, s)))\n",
    "print(np.percentile(l,99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 33\n",
    "\n",
    "# Create word_to_idx and tag_to_idx mappings\n",
    "word_to_idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "fine_tag_to_idx = {\"<PAD>\": 0}\n",
    "coarse_tag_to_idx = {\"<PAD>\": 0}\n",
    "\n",
    "\n",
    "def preprocess(dataset):\n",
    "    # Extract sentences and tags\n",
    "    sent = [[token.lower() for token, fine_tag, coarse_tag in sentence] for sentence in dataset]\n",
    "    fine_tags = [[fine_tag for token, fine_tag, coarse_tag in sentence] for sentence in dataset]\n",
    "    coarse_tags = [[coarse_tag for token, fine_tag, coarse_tag in sentence] for sentence in dataset]\n",
    "\n",
    "    for i in range(len(sent)):\n",
    "        while len(sent[i]) < SEQ_LEN:\n",
    "            sent[i].append('<PAD>')\n",
    "            fine_tags[i].append('<PAD>')\n",
    "            coarse_tags[i].append('<PAD>')\n",
    "\n",
    "        if len(sent[i]) > SEQ_LEN:\n",
    "            sent[i] = sent[i][:SEQ_LEN]\n",
    "            fine_tags[i] = fine_tags[i][:SEQ_LEN]\n",
    "            coarse_tags[i] = coarse_tags[i][:SEQ_LEN]\n",
    "    \n",
    "    for sentence_tags in fine_tags:\n",
    "        for fine_tag in sentence_tags:\n",
    "            if fine_tag not in fine_tag_to_idx:\n",
    "                # word = nlp(fine_tag)\n",
    "                fine_tag_to_idx[fine_tag] = len(fine_tag)\n",
    "\n",
    "    for sentence_tags in coarse_tags:\n",
    "        for coarse_tag in sentence_tags:\n",
    "            if coarse_tag not in coarse_tag_to_idx:\n",
    "                # word = nlp(coarse_tag)\n",
    "                coarse_tag_to_idx[coarse_tag] = len(coarse_tag)\n",
    "    \n",
    "    for sentence in sent:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_idx:\n",
    "                # word = nlp(word)\n",
    "                word_to_idx[word] = len(word)\n",
    "\n",
    "    # Convert words and tags to indices\n",
    "    X = torch.tensor([[word_to_idx.get(word, 1) for word in sentence] for sentence in sent], dtype=torch.float32).type(torch.LongTensor)\n",
    "    fine_Y = torch.tensor([[fine_tag_to_idx[fine_tag] for fine_tag in sentence] for sentence in fine_tags]).type(torch.LongTensor)\n",
    "    coarse_Y = torch.tensor([[coarse_tag_to_idx[coarse_tag] for coarse_tag in sentence] for sentence in coarse_tags]).type(torch.LongTensor)\n",
    "    \n",
    "    return X, fine_Y, coarse_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_fine_Y, train_coarse_Y = preprocess(train_dataset)\n",
    "# len(train_X), len(train_fine_Y), len(train_coarse_Y)\n",
    "dev_X, dev_fine_Y, dev_coarse_Y = preprocess(dev_dataset)\n",
    "test_X, test_fine_Y, test_coarse_Y = preprocess(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class NERModel(pl.LightningModule):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim, num_layers=1, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim) #B * seq_len, B * seq_len * embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=num_layers, bidirectional=bidirectional)\n",
    "        #B * seq_len * embedding_dim -> B * seq_len * hidden_dim \n",
    "        #tags\n",
    "        if bidirectional:\n",
    "            self.fc = nn.Linear(2*hidden_dim, tagset_size)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        #print(embeds.shape)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        tag_space = self.fc(lstm_out)\n",
    "        tag_scores = nn.functional.log_softmax(tag_space, dim=2)\n",
    "        return tag_scores\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn(y_hat.view(-1, y_hat.shape[-1]), y.view(-1))\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn(y_hat.view(-1, y_hat.shape[-1]), y.view(-1))\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn(y_hat.view(-1, y_hat.shape[-1]), y.view(-1))\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of the model on fine-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM    = 100\n",
    "NUM_EPOCHS    = 10 \n",
    "BATCH_SIZE    = 5\n",
    "\n",
    "train_dataset = TensorDataset(train_X, train_fine_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(dev_X, dev_fine_Y)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset = TensorDataset(test_X, test_fine_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/friday/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | embedding | Embedding        | 3.1 M \n",
      "1 | lstm      | LSTM             | 161 K \n",
      "2 | fc        | Linear           | 7.0 K \n",
      "3 | loss_fn   | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "3.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.921    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389982b78c2446cc88a4049258584bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/friday/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/friday/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7f9898ae49405fbb8e20825fe2a12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c2ab7efeac4cc9b3dedc1070e2708a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050be01520c94facbf327bcc544b3a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79167d194c724c06b295cce5fe9d279c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7dcca659f49448cbf40dccfee6cc69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eac5850a6094ea9a374e6f04853527e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df67eaf2219b426ea6a2ab0576d53508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c31f6e60de45ecb452376f89fa7f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a80ed59b404dad98a63ca629a8c849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60355e95c35a44a2afd5c374efb60212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c386ffbe00479bac91b40fd9255afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "/home/friday/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:148: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at /home/friday/Documents/MS/Coursework/1st Sem/Deep Learning/DL23-CS60010/assignment-2/lightning_logs/version_8/checkpoints/epoch=9-step=19270.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/friday/Documents/MS/Coursework/1st Sem/Deep Learning/DL23-CS60010/assignment-2/lightning_logs/version_8/checkpoints/epoch=9-step=19270.ckpt\n",
      "/home/friday/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adc4a7572e64718ab0f3970d61e523c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.31005585193634033    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.31005585193634033   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.31005585193634033}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NERModel(vocab_size=len(word_to_idx), tagset_size=len(fine_tag_to_idx), embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, bidirectional=True)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
    "trainer = pl.Trainer(max_epochs=NUM_EPOCHS, accelerator='gpu', callbacks=[early_stopping])\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "# trainer.save_checkpoint(\"english.ckpt\")\n",
    "\n",
    "trainer.test(dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/friday/envs/deep/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/friday/envs/deep/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                <PAD>       1.00      1.00      1.00    312309\n",
      "AerospaceManufacturer       0.13      0.01      0.02       179\n",
      "  AnatomicalStructure       0.00      0.00      0.00       599\n",
      "              ArtWork       0.41      0.13      0.20      6066\n",
      "      CarManufacturer       0.55      0.08      0.14      7753\n",
      "               Cleric       0.23      0.03      0.05      4172\n",
      "                Drink       0.00      0.00      0.00       199\n",
      "                 Food       0.50      0.01      0.02       579\n",
      "     MedicalProcedure       0.18      0.04      0.07       560\n",
      "   Medication/Vaccine       0.40      0.00      0.01       516\n",
      "          MusicalWork       0.28      0.06      0.10      2238\n",
      "                    O       0.88      0.99      0.93    250839\n",
      "                  ORG       0.84      0.39      0.53      4895\n",
      "           PublicCorp       0.25      0.04      0.08      5693\n",
      "            Scientist       0.23      0.23      0.23      4548\n",
      "             Software       0.24      0.03      0.06      4870\n",
      "        SportsManager       0.03      0.00      0.00      1152\n",
      "\n",
      "             accuracy                           0.93    607167\n",
      "            macro avg       0.36      0.18      0.20    607167\n",
      "         weighted avg       0.90      0.93      0.91    607167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/friday/envs/deep/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# define idx_to_tag\n",
    "idx_to_tag = {idx: fine_tag for fine_tag, idx in fine_tag_to_idx.items()}\n",
    "\n",
    "# define device\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Create a dataloader for the test set\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "fine_y_true = []\n",
    "fine_y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, fine_y in test_loader:\n",
    "        # Move the data to the device\n",
    "        x = x.to(device)\n",
    "        fine_y = fine_y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        fine_y_hat = model(x)\n",
    "\n",
    "        # Compute the predicted tags\n",
    "        fine_y_pred += [idx_to_tag[i] for i in fine_y_hat.argmax(-1).cpu().numpy().flatten().tolist()]\n",
    "\n",
    "        # Compute the true tags\n",
    "        fine_y_true += [idx_to_tag[i] for i in fine_y.cpu().numpy().flatten().tolist()]\n",
    "\n",
    "print(classification_report(fine_y_true, fine_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <PAD>       1.00      0.98      0.99    318002\n",
      "CreativeWork       0.41      0.10      0.16     13174\n",
      "       Group       0.78      0.21      0.33     12827\n",
      "     Medical       0.20      0.02      0.03      1675\n",
      "           O       0.88      0.99      0.93    250839\n",
      "      Person       0.30      0.15      0.20      9872\n",
      "     Product       0.50      0.01      0.01       778\n",
      "\n",
      "    accuracy                           0.93    607167\n",
      "   macro avg       0.58      0.35      0.38    607167\n",
      "weighted avg       0.92      0.93      0.92    607167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coarse_y_true = list(map(coarse_tag, fine_y_true))\n",
    "coarse_y_pred = list(map(coarse_tag, fine_y_pred))\n",
    "print(classification_report(coarse_y_true, coarse_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to predict NERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence\n",
      "['शायर', 'प्राचीनता', 'victoria', 'ईव', '३१२', 'शायर', 'ईव', 'शायर', 'शायर', 'जन्म।', 'रॉकलिफ', 'रॉकलिफ', 'ईव', 'ईव', 'ईव', '३१२', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '३१२', 'रॉकलिफ', '♀', 'शायर', 'शायर', '♀', 'रॉकलिफ', 'रॉकलिफ', 'जन्म।', 'ईव', '३१२', 'रॉकलिफ', '३१२', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'ईव', 'victoria', '८१२/८१३', 'victoria', 'रॉकलिफ', 'जन्म।', 'रॉकलिफ', 'ईव', '३१२', '८१२/८१३', 'ईव', 'ईव', 'ईव', '३१२', 'ईव', '३१२', '८१२/८१३', 'रॉकलिफ', 'ईव', '३१२', 'शायर', '३१२', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'रॉकलिफ', 'ईव', '३१२', 'जन्म।', '३१२', '३१२', '३१२', 'रॉकलिफ', 'शायर', 'शायर', '८१२/८१३', 'शायर', 'victoria', 'ईव', '३१२', 'शायर', '८१२/८१३', 'ईव', 'जन्म।', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '३१२', 'शायर', '३१२', 'जन्म।', '३१२', '३१२', '८१२/८१३', 'ईव', '३१२', 'जन्म।', 'ईव', '३१२', 'टैक्सोनोमिक', '३१२', '३१२', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Predicted tags\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'Scientist', 'Cleric', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'Person', 'Person', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "fine_y_true = []\n",
    "fine_y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        # Move the data to the device\n",
    "        x = x.to(device)\n",
    "        fine_y = fine_y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        fine_y_hat = model(x)\n",
    "\n",
    "        # Get back the sentence\n",
    "        x_sent = [idx_to_word[i] for i in x.cpu().numpy().flatten().tolist()]\n",
    "\n",
    "        # Compute the predicted tags\n",
    "        fine_y_pred += [idx_to_tag[i] for i in fine_y_hat.argmax(-1).cpu().numpy().flatten().tolist()]\n",
    "\n",
    "        # Compute the true tags\n",
    "        fine_y_true += [idx_to_tag[i] for i in fine_y.cpu().numpy().flatten().tolist()]\n",
    "        print(\"Sentence\")\n",
    "        print(x_sent)\n",
    "        print(\"Predicted tags\")\n",
    "        print(fine_y_pred)\n",
    "        coarse_y_pred = list(map(coarse_tag, fine_y_pred))\n",
    "        print(coarse_y_pred)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
