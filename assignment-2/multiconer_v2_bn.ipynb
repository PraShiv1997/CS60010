{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "#from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coarse_tag(tag):\n",
    "  LOC = ['Facility', 'OtherLOC', 'HumanSettlement', 'Station']\n",
    "  CW = ['VisualWork', 'MusicalWork', 'WrittenWork', 'ArtWork', 'Software']\n",
    "  GRP = ['MusicalGRP', 'PublicCORP', 'PrivateCORP', 'AerospaceManufacturer', 'SportsGRP', 'CarManufacturer', 'ORG']\n",
    "  PER = ['Scientist', 'Artist', 'Athlete', 'Politician', 'Cleric', 'SportsManager', 'OtherPER']\n",
    "  PROD = ['Clothing', 'Vehicle', 'Food', 'Drink', 'OtherPROD']\n",
    "  MED = ['Medication/Vaccine', 'MedicalProcedure', 'AnatomicalStructure', 'Symptom', 'Disease']\n",
    "  if tag in LOC:\n",
    "    return('Location')\n",
    "  elif tag in CW:\n",
    "    return('CreativeWork')\n",
    "  elif tag in GRP:\n",
    "    return('Group')\n",
    "  elif tag in PER:\n",
    "    return('Person')\n",
    "  elif tag in PROD:\n",
    "    return('Product')\n",
    "  elif tag in MED:\n",
    "    return('Medical')\n",
    "  elif tag == 'O':\n",
    "    return('O')\n",
    "  else:\n",
    "    return('<PAD>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(file):\n",
    "  unclean_txt = re.compile(\"^#|[\\n]\")\n",
    "  data = []\n",
    "  with open(file) as f:\n",
    "      sent = []\n",
    "      for i in f.read().splitlines():\n",
    "          if unclean_txt.match(i) == None:\n",
    "              s = i.split(' _ _ ')[0]\n",
    "              t = i.split(' _ _ ')[-1]\n",
    "              if s!='' and t != '':\n",
    "                if t != 'O':\n",
    "                  t = t[2:]\n",
    "                z = coarse_tag(t)\n",
    "                sent.append((s,t,z))\n",
    "          if unclean_txt.match(i):\n",
    "              data.append(sent)\n",
    "              sent = []\n",
    "      data.append(sent)\n",
    "  data = data[1:] # first line had a new line character\n",
    "  return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset('/home/friday/Documents/MS/Coursework/1st Sem/Deep Learning/DL23-CS60010/assignment-2/multiconer2023/BN-Bangla/bn_train.conll')\n",
    "dev_dataset = make_dataset('/home/friday/Documents/MS/Coursework/1st Sem/Deep Learning/DL23-CS60010/assignment-2/multiconer2023/BN-Bangla/bn_dev.conll')\n",
    "test_dataset = make_dataset('/home/friday/Documents/MS/Coursework/1st Sem/Deep Learning/DL23-CS60010/assignment-2/multiconer2023/BN-Bangla/bn_test.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('স্টেশনটি', 'O', 'O'),\n",
       " ('প্ল্যাটফর্ম', 'OtherPROD', 'Product'),\n",
       " ('স্ক্রিন', 'OtherPROD', 'Product'),\n",
       " ('ডোর', 'OtherPROD', 'Product'),\n",
       " ('দিয়ে', 'O', 'O'),\n",
       " ('সজ্জিত।', 'O', 'O')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.0\n"
     ]
    }
   ],
   "source": [
    "s = [[token.lower() for token, fine_tag, coarse_tag  in sentence] for sentence in train_dataset]\n",
    "l = np.array(list(map(len, s)))\n",
    "print(np.percentile(l,99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 26\n",
    "\n",
    "# Create word_to_idx and tag_to_idx mappings\n",
    "word_to_idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "fine_tag_to_idx = {\"<PAD>\": 0}\n",
    "coarse_tag_to_idx = {\"<PAD>\": 0}\n",
    "\n",
    "\n",
    "def preprocess(dataset):\n",
    "    # Extract sentences and tags\n",
    "    sent = [[token.lower() for token, fine_tag, coarse_tag in sentence] for sentence in dataset]\n",
    "    fine_tags = [[fine_tag for token, fine_tag, coarse_tag in sentence] for sentence in dataset]\n",
    "    coarse_tags = [[coarse_tag for token, fine_tag, coarse_tag in sentence] for sentence in dataset]\n",
    "\n",
    "    for i in range(len(sent)):\n",
    "        while len(sent[i]) < SEQ_LEN:\n",
    "            sent[i].append('<PAD>')\n",
    "            fine_tags[i].append('<PAD>')\n",
    "            coarse_tags[i].append('<PAD>')\n",
    "\n",
    "        if len(sent[i]) > SEQ_LEN:\n",
    "            sent[i] = sent[i][:SEQ_LEN]\n",
    "            fine_tags[i] = fine_tags[i][:SEQ_LEN]\n",
    "            coarse_tags[i] = coarse_tags[i][:SEQ_LEN]\n",
    "    \n",
    "    for sentence_tags in fine_tags:\n",
    "        for fine_tag in sentence_tags:\n",
    "            if fine_tag not in fine_tag_to_idx:\n",
    "                # word = nlp(fine_tag)\n",
    "                fine_tag_to_idx[fine_tag] = len(fine_tag)\n",
    "\n",
    "    for sentence_tags in coarse_tags:\n",
    "        for coarse_tag in sentence_tags:\n",
    "            if coarse_tag not in coarse_tag_to_idx:\n",
    "                # word = nlp(coarse_tag)\n",
    "                coarse_tag_to_idx[coarse_tag] = len(coarse_tag)\n",
    "    \n",
    "    for sentence in sent:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_idx:\n",
    "                # word = nlp(word)\n",
    "                word_to_idx[word] = len(word)\n",
    "\n",
    "    # Convert words and tags to indices\n",
    "    X = torch.tensor([[word_to_idx.get(word, 1) for word in sentence] for sentence in sent], dtype=torch.float32).type(torch.LongTensor)\n",
    "    fine_Y = torch.tensor([[fine_tag_to_idx[fine_tag] for fine_tag in sentence] for sentence in fine_tags]).type(torch.LongTensor)\n",
    "    coarse_Y = torch.tensor([[coarse_tag_to_idx[coarse_tag] for coarse_tag in sentence] for sentence in coarse_tags]).type(torch.LongTensor)\n",
    "    \n",
    "    return X, fine_Y, coarse_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_fine_Y, train_coarse_Y = preprocess(train_dataset)\n",
    "# len(train_X), len(train_fine_Y), len(train_coarse_Y)\n",
    "dev_X, dev_fine_Y, dev_coarse_Y = preprocess(dev_dataset)\n",
    "test_X, test_fine_Y, test_coarse_Y = preprocess(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class NERModel(pl.LightningModule):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim, num_layers=1, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim) #B * seq_len, B * seq_len * embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=num_layers, bidirectional=bidirectional)\n",
    "        #B * seq_len * embedding_dim -> B * seq_len * hidden_dim \n",
    "        #tags\n",
    "        if bidirectional:\n",
    "            self.fc = nn.Linear(2*hidden_dim, tagset_size)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        #print(embeds.shape)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        tag_space = self.fc(lstm_out)\n",
    "        tag_scores = nn.functional.log_softmax(tag_space, dim=2)\n",
    "        return tag_scores\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn(y_hat.view(-1, y_hat.shape[-1]), y.view(-1))\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn(y_hat.view(-1, y_hat.shape[-1]), y.view(-1))\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn(y_hat.view(-1, y_hat.shape[-1]), y.view(-1))\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of the model on fine-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM    = 100\n",
    "NUM_EPOCHS    = 10 \n",
    "BATCH_SIZE    = 5\n",
    "\n",
    "train_dataset = TensorDataset(train_X, train_fine_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(dev_X, dev_fine_Y)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset = TensorDataset(test_X, test_fine_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/friday/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | embedding | Embedding        | 4.3 M \n",
      "1 | lstm      | LSTM             | 161 K \n",
      "2 | fc        | Linear           | 7.0 K \n",
      "3 | loss_fn   | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.715    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21494835b57f43a38ec5926a9e6353f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/friday/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/friday/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cac323b5500472083ffff1f20de1a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51593fffd0a24d389aa0d38b87bc8898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a01fc34a7e4788a2474e30177d8a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0ad855976746bb999192f2169e29d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4bfaf8ce2d4fd09f8d68bb48057380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4639aa08eb84c86847bd1f179cdbc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfe9a2ae98f4d8583f0c573b0cc5513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0296e80917ca4d37980bfa9c1047a3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013b4041b68f4d0cb926cc6c6b65d26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08fd7ceab03e47e7adf8e66c227c36fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835da8706a3146589fdc9d1be8a9f99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "/home/friday/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:148: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at /home/friday/Documents/MS/Coursework/1st Sem/Deep Learning/DL23-CS60010/assignment-2/lightning_logs/version_7/checkpoints/epoch=9-step=19420.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/friday/Documents/MS/Coursework/1st Sem/Deep Learning/DL23-CS60010/assignment-2/lightning_logs/version_7/checkpoints/epoch=9-step=19420.ckpt\n",
      "/home/friday/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f920c84a2274a9f8f9f615d824d8852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3757822811603546     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3757822811603546    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.3757822811603546}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NERModel(vocab_size=len(word_to_idx), tagset_size=len(fine_tag_to_idx), embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, bidirectional=True)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
    "trainer = pl.Trainer(max_epochs=NUM_EPOCHS, accelerator='gpu', callbacks=[early_stopping])\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "# trainer.save_checkpoint(\"english.ckpt\")\n",
    "\n",
    "trainer.test(dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                <PAD>       1.00      1.00      1.00    260297\n",
      "AerospaceManufacturer       0.00      0.00      0.00       211\n",
      "  AnatomicalStructure       0.32      0.06      0.10       623\n",
      "              ArtWork       0.24      0.08      0.12      5579\n",
      "      CarManufacturer       0.54      0.23      0.33      7824\n",
      "               Cleric       0.21      0.01      0.03      6145\n",
      "             Clothing       0.19      0.10      0.13      5911\n",
      "                Drink       0.00      0.00      0.00       141\n",
      "                 Food       0.13      0.01      0.01       628\n",
      "     MedicalProcedure       0.13      0.02      0.04       421\n",
      "   Medication/Vaccine       0.18      0.01      0.03       636\n",
      "          MusicalWork       0.50      0.08      0.13      3500\n",
      "                    O       0.85      0.98      0.91    208934\n",
      "                  ORG       0.74      0.33      0.45      4929\n",
      "            SportsGRP       0.44      0.17      0.24      3598\n",
      "        SportsManager       0.17      0.01      0.01       400\n",
      "           VisualWork       0.16      0.05      0.07      6557\n",
      "\n",
      "             accuracy                           0.91    516334\n",
      "            macro avg       0.34      0.18      0.21    516334\n",
      "         weighted avg       0.88      0.91      0.89    516334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# define idx_to_tag\n",
    "idx_to_tag = {idx: fine_tag for fine_tag, idx in fine_tag_to_idx.items()}\n",
    "\n",
    "# define device\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Create a dataloader for the test set\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "fine_y_true = []\n",
    "fine_y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, fine_y in test_loader:\n",
    "        # Move the data to the device\n",
    "        x = x.to(device)\n",
    "        fine_y = fine_y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        fine_y_hat = model(x)\n",
    "\n",
    "        # Compute the predicted tags\n",
    "        fine_y_pred += [idx_to_tag[i] for i in fine_y_hat.argmax(-1).cpu().numpy().flatten().tolist()]\n",
    "\n",
    "        # Compute the true tags\n",
    "        fine_y_true += [idx_to_tag[i] for i in fine_y.cpu().numpy().flatten().tolist()]\n",
    "\n",
    "print(classification_report(fine_y_true, fine_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <PAD>       1.00      1.00      1.00    260297\n",
      "CreativeWork       0.35      0.09      0.14     15636\n",
      "       Group       0.63      0.27      0.38     16562\n",
      "     Medical       0.25      0.03      0.06      1680\n",
      "           O       0.85      0.98      0.91    208934\n",
      "      Person       0.22      0.01      0.03      6545\n",
      "     Product       0.20      0.09      0.12      6680\n",
      "\n",
      "    accuracy                           0.91    516334\n",
      "   macro avg       0.50      0.35      0.38    516334\n",
      "weighted avg       0.89      0.91      0.89    516334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coarse_y_true = list(map(coarse_tag, fine_y_true))\n",
    "coarse_y_pred = list(map(coarse_tag, fine_y_pred))\n",
    "print(classification_report(coarse_y_true, coarse_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to predict NERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence\n",
      "['ক্যালিপার্স', 'মুঠো', 'ডো', 'প্রোটোকলগুলির', 'ব্যান্ডউইথের', 'বিন্দুটি', 'রুবিক', 'রিল', 'মুঠো', 'মুঠো', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'রিল', 'মুঠো', 'মুঠো', 'মুঠো', 'মুঠো', 'মুঠো', 'বিন্দুটি', 'রিল', 'রুবিক', 'এ৮এক্স', 'এ৮এক্স', 'রিল', 'বিন্দুটি', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'এ৮এক্স', 'মুঠো', 'রুবিক', 'পাম্পজ্যাক', 'এ৮এক্স', 'বিন্দুটি', 'মুঠো', 'এ৮এক্স', 'এ৮এক্স', 'রিল', 'জ্যানাস', 'মুঠো', 'বিন্দুটি', 'মুঠো', 'রুবিক', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'বিন্দুটি', 'মুঠো', 'মুঠো', 'ব্যান্ডউইথের', 'পাম্পজ্যাক', 'জ্যানাস', 'বিন্দুটি', 'রিল', 'বিন্দুটি', 'ʻ', 'বিন্দুটি', 'মুঠো', 'ʻ', 'মুঠো', 'বিন্দুটি', 'মুঠো', 'তেলফিল্ডে', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'মুঠো', 'মুঠো', 'অভিব্যক্তিগুলি', 'জ্যানাস', 'এ৮এক্স', 'ডো', 'ক্যালিপার্স', 'মুঠো', 'রিল', 'বিন্দুটি', 'তেলফিল্ডে', 'রিল', 'জ্যানাস', 'এ৮এক্স', 'এ৮এক্স', 'জ্যানাস', 'মুঠো', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Predicted tags\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'O', 'O', 'O', 'O', 'CarManufacturer', 'O', 'SportsGRP', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'CarManufacturer', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'Clothing', 'Clothing', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'O', 'O', 'O', 'O', 'Group', 'O', 'Group', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'Group', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'O', 'O', 'Product', 'Product', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "fine_y_true = []\n",
    "fine_y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        # Move the data to the device\n",
    "        x = x.to(device)\n",
    "        fine_y = fine_y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        fine_y_hat = model(x)\n",
    "\n",
    "        # Get back the sentence\n",
    "        x_sent = [idx_to_word[i] for i in x.cpu().numpy().flatten().tolist()]\n",
    "\n",
    "        # Compute the predicted tags\n",
    "        fine_y_pred += [idx_to_tag[i] for i in fine_y_hat.argmax(-1).cpu().numpy().flatten().tolist()]\n",
    "\n",
    "        # Compute the true tags\n",
    "        fine_y_true += [idx_to_tag[i] for i in fine_y.cpu().numpy().flatten().tolist()]\n",
    "        print(\"Sentence\")\n",
    "        print(x_sent)\n",
    "        print(\"Predicted tags\")\n",
    "        print(fine_y_pred)\n",
    "        coarse_y_pred = list(map(coarse_tag, fine_y_pred))\n",
    "        print(coarse_y_pred)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
